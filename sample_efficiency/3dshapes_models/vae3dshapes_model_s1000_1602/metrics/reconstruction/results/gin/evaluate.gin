# Parameters for AdamOptimizer:
# ==============================================================================
AdamOptimizer.beta1 = 0.9
AdamOptimizer.beta2 = 0.999
AdamOptimizer.epsilon = 1e-08
AdamOptimizer.learning_rate = 0.0001
AdamOptimizer.name = 'Adam'
AdamOptimizer.use_locking = False

# Parameters for dataset:
# ==============================================================================
dataset.name = '3dshapes_task'

# Parameters for decoder:
# ==============================================================================
decoder.decoder_fn = @deconv_decoder

# Parameters for decoder_optimizer:
# ==============================================================================
decoder_optimizer.learning_rate = None
decoder_optimizer.optimizer_fn = @AdamOptimizer

# Parameters for deconv_decoder:
# ==============================================================================
# None.

# Parameters for downstream_decoder:
# ==============================================================================
# None.

# Parameters for downstream_model.export_as_tf_hub:
# ==============================================================================
downstream_model.export_as_tf_hub.drop_collections = None

# Parameters for l2_loss:
# ==============================================================================
# None.

# Parameters for reconstruction_loss:
# ==============================================================================
reconstruction_loss.activation = 'logits'
reconstruction_loss.loss_fn = @l2_loss

# Parameters for supervised_model:
# ==============================================================================
supervised_model.batch_size = 64
supervised_model.eval_steps = 1
supervised_model.model = @downstream_decoder()
supervised_model.model_num = None
supervised_model.name = ''
supervised_model.random_seed = 1602
supervised_model.training_steps = 5
